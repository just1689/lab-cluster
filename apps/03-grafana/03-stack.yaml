---
# Source: grafana/templates/podsecuritypolicy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default'
    seccomp.security.alpha.kubernetes.io/defaultProfileName:  'docker/default'
    apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'
    apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    # Default set from Docker, without DAC_OVERRIDE or CHOWN
    - FOWNER
    - FSETID
    - KILL
    - SETGID
    - SETUID
    - SETPCAP
    - NET_BIND_SERVICE
    - NET_RAW
    - SYS_CHROOT
    - MKNOD
    - AUDIT_WRITE
    - SETFCAP
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  hostNetwork: false
  hostIPC: false
  hostPID: false
  runAsUser:
    rule: 'RunAsAny'
  seLinux:
    rule: 'RunAsAny'
  supplementalGroups:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
  readOnlyRootFilesystem: false
---
# Source: grafana/templates/tests/test-podsecuritypolicy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: monitoring-grafana-test
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
spec:
  allowPrivilegeEscalation: true
  privileged: false
  hostNetwork: false
  hostIPC: false
  hostPID: false
  fsGroup:
    rule: RunAsAny
  seLinux:
    rule: RunAsAny
  supplementalGroups:
    rule: RunAsAny
  runAsUser:
    rule: RunAsAny
  volumes:
  - configMap
  - downwardAPI
  - emptyDir
  - projected
  - secret
---
# Source: grafana/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana
  namespace: monitoring
---
# Source: grafana/templates/tests/test-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana-test
  namespace: monitoring
---
# Source: grafana/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  admin-user: "YWRtaW4="
  admin-password: "SHZIVjhVOFl2RDRQRVdwQWYzVGhNQW5ZVU5BVVZkUnA4cUZlSDdmdA=="
  ldap-toml: ""
---
# Source: grafana/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
data:
  grafana.ini: |
    [analytics]
    check_for_updates = true
    [grafana_net]
    url = https://grafana.net
    [log]
    mode = console
    [paths]
    data = /var/lib/grafana/data
    logs = /var/log/grafana
    plugins = /var/lib/grafana/plugins
    provisioning = /etc/grafana/provisioning
---
# Source: grafana/templates/tests/test-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: monitoring-grafana-test
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
data:
  run.sh: |-
    @test "Test Health" {
      url="http://monitoring-grafana/api/health"

      code=$(wget --server-response --spider --timeout 10 --tries 1 ${url} 2>&1 | awk '/^  HTTP/{print $2}')
      [ "$code" == "200" ]
    }
---
# Source: grafana/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
  name: monitoring-grafana-clusterrole
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["configmaps", "secrets"]
  verbs: ["get", "watch", "list"]
---
# Source: grafana/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: monitoring-grafana-clusterrolebinding
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: monitoring-grafana
    namespace: monitoring
roleRef:
  kind: ClusterRole
  name: monitoring-grafana-clusterrole
  apiGroup: rbac.authorization.k8s.io
---
# Source: grafana/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: Role
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['extensions']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [monitoring-grafana]
---
# Source: grafana/templates/tests/test-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: monitoring-grafana-test
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:      ['policy']
  resources:      ['podsecuritypolicies']
  verbs:          ['use']
  resourceNames:  [monitoring-grafana-test]
---
# Source: grafana/templates/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: monitoring-grafana
subjects:
- kind: ServiceAccount
  name: monitoring-grafana
  namespace: monitoring
---
# Source: grafana/templates/tests/test-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: monitoring-grafana-test
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: monitoring-grafana-test
subjects:
- kind: ServiceAccount
  name: monitoring-grafana-test
  namespace: monitoring
---
# Source: grafana/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: service
      port: 80
      protocol: TCP
      targetPort: 3000

  selector:
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
---
# Source: grafana/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: monitoring-grafana
  namespace: monitoring
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: grafana
      app.kubernetes.io/instance: monitoring
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: grafana
        app.kubernetes.io/instance: monitoring
      annotations:
        checksum/config: b1d156a2d1bd33933c2ab1b0cd26cbaf5ba6601532ba0b18342ce739e0ce29b9
        checksum/dashboards-json-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/sc-dashboard-provider-config: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
        checksum/secret: be2cda3e9e3b646b1d76e1243e24a843e0b86d245d7d4f8e016f985f9db46da9
    spec:
      
      serviceAccountName: monitoring-grafana
      securityContext:
        fsGroup: 472
        runAsGroup: 472
        runAsUser: 472
      initContainers:
        - name: grafana-sc-datasources
          image: "kiwigrid/k8s-sidecar:0.1.151"
          imagePullPolicy: IfNotPresent
          env:
            - name: METHOD
              value: LIST
            - name: LABEL
              value: "grafana_datasource"
            - name: FOLDER
              value: "/etc/grafana/provisioning/datasources"
            - name: RESOURCE
              value: "both"
          resources:
            {}
          volumeMounts:
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
      containers:
        - name: grafana
          image: "grafana/grafana:7.1.1"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: "/etc/grafana/grafana.ini"
              subPath: grafana.ini
            - name: storage
              mountPath: "/var/lib/grafana"
            - name: sc-datasources-volume
              mountPath: "/etc/grafana/provisioning/datasources"
          ports:
            - name: service
              containerPort: 80
              protocol: TCP
            - name: grafana
              containerPort: 3000
              protocol: TCP
          env:
            - name: GF_SECURITY_ADMIN_USER
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-user
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: monitoring-grafana
                  key: admin-password
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /api/health
              port: 3000
            initialDelaySeconds: 60
            timeoutSeconds: 30
          readinessProbe:
            httpGet:
              path: /api/health
              port: 3000
          resources:
            {}
      volumes:
        - name: config
          configMap:
            name: monitoring-grafana
        - name: storage
          emptyDir: {}
        - name: sc-datasources-volume
          emptyDir: {}
---
# Source: grafana/templates/tests/test.yaml
apiVersion: v1
kind: Pod
metadata:
  name: monitoring-grafana-test
  labels:
    helm.sh/chart: grafana-5.5.5
    app.kubernetes.io/name: grafana
    app.kubernetes.io/instance: monitoring
    app.kubernetes.io/version: "7.1.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
  namespace: monitoring
spec:
  serviceAccountName: monitoring-grafana-test
  containers:
    - name: monitoring-test
      image: "bats/bats:v1.1.0"
      imagePullPolicy: "IfNotPresent"
      command: ["/opt/bats/bin/bats", "-t", "/tests/run.sh"]
      volumeMounts:
        - mountPath: /tests
          name: tests
          readOnly: true
  volumes:
  - name: tests
    configMap:
      name: monitoring-grafana-test
  restartPolicy: Never
